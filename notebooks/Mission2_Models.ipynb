{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Mission 2: Modélisation et tracking des expériences**",
   "id": "369f8caa0d2e6358"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Objectifs principaux :\n",
    "\n",
    "Construire un modèle de régression linéaire comme baseline.\n",
    "\n",
    "Explorer des modèles avancés (Random Forest, Gradient Boosting).\n",
    "\n",
    "Suivre les expériences avec MLflow.\n",
    "\n",
    "Enregistrer le meilleur modèle."
   ],
   "id": "8b17008cf9384a63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dans cette section, nous nous concentrons sur l’évaluation des performances des différents modèles de régression en utilisant plusieurs configurations de paramètres. L’objectif principal est de comparer les modèles sur la base de métriques pertinentes telles que l’erreur quadratique moyenne (MSE), la racine carrée de l’erreur quadratique moyenne (RMSE), l’erreur absolue moyenne (MAE) et le coefficient de détermination (R²).",
   "id": "5b11fb4ba7fad90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **1- Régression linéaire**",
   "id": "476eed4a74bf3cab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nous commencerons par construire un modèle de régression linéaire servant de baseline. Ce modèle, simple et interprétable, fournira une première référence pour évaluer la qualité des prédictions. Ensuite, nous explorerons des modèles plus avancés, notamment le Random Forest Regressor et le Gradient Boosting Regressor",
   "id": "712a7d3e83696b0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:12:08.236834Z",
     "start_time": "2025-01-17T17:11:51.438794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données\n",
    "file_path = '../data/processed/housing_standardized.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Définir (features) et la variable cible (target)\n",
    "X = data.drop(columns=['MedHouseVal'])\n",
    "y = data['MedHouseVal']\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de tests\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Début de l'expérience MLflow\n",
    "mlflow.set_experiment(\"California Housing Linear Regression\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Linear Regression Model\"):\n",
    "    # Initialiser et entraîner le modèle\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcul des métriques\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Racine carrée du MSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Enregistrer les paramètres\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    # Enregistrer les métriques\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R-squared\", r2)\n",
    "\n",
    "    # Afficher les métriques\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "\n",
    "    # Enregistrer le modèle\n",
    "    mlflow.sklearn.log_model(model, \"linear_regression_model\")\n",
    "    print(\"Modèle enregistré dans MLflow.\")"
   ],
   "id": "2524b394fb188762",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/17 18:11:51 INFO mlflow.tracking.fluent: Experiment with name 'California Housing Linear Regression' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.4059262952701108\n",
      "Root Mean Squared Error (RMSE): 0.63712345371216\n",
      "Mean Absolute Error (MAE): 0.4714992246236078\n",
      "R-squared: 0.6522131659556444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/17 18:12:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré dans MLflow.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "MSE (0.4059) et RMSE (0.6371) : Ces valeurs indiquent des erreurs relativement élevées dans les prédictions, montrant que le modèle n'est pas très précis.\n",
    "\n",
    "MAE (0.4715) : L'écart moyen entre les prédictions et les valeurs réelles est de 0.4715, ce qui est notable.\n",
    "\n",
    "R² (0.6522) : Le modèle explique environ 65% de la variance des données, ce qui est raisonnable, mais il y a encore de la place pour améliorer la précision."
   ],
   "id": "8a37acae6c1e6194"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **2-Random Forest Model**",
   "id": "f4dba3afd51f3cc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:21:34.418068Z",
     "start_time": "2025-01-17T17:21:10.876940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données\n",
    "file_path = '../data/processed/housing_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Définir (features) et la variable cible (target)\n",
    "X = data.drop(columns=['MedHouseVal'])\n",
    "y = data['MedHouseVal']\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Début de l'expérience MLflow\n",
    "mlflow.set_experiment(\"California Housing Random Forest\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Random Forest Model\") as run:\n",
    "    # Initialiser et entraîner le modèle Random Forest\n",
    "    model = RandomForestRegressor(n_estimators=80, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcul des métriques\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Racine carrée du MSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Enregistrer les paramètres\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"n_estimators\", 80)\n",
    "\n",
    "    # Enregistrer les métriques\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R-squared\", r2)\n",
    "\n",
    "    # Afficher les métriques\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "\n",
    "    # Enregistrer le modèle dans les artifacts\n",
    "    model_name = \"random_forest_model\"\n",
    "    mlflow.sklearn.log_model(model, model_name)\n",
    "    print(\"Modèle enregistré dans les artifacts de MLflow.\")\n",
    "\n",
    "    # Enregistrer dans le Model Registry\n",
    "    registered_model_name = \"CaliforniaHousingRandomForest\"\n",
    "    model_uri = f\"runs:/{run.info.run_id}/{model_name}\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=registered_model_name)\n",
    "    print(f\"Modèle enregistré dans le Model Registry avec le nom : {registered_model_name}\")"
   ],
   "id": "adccf0080c65134f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/17 18:21:11 INFO mlflow.tracking.fluent: Experiment with name 'California Housing Random Forest' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.23157209638015866\n",
      "Root Mean Squared Error (RMSE): 0.48121938487571203\n",
      "Mean Absolute Error (MAE): 0.31549043595747844\n",
      "R-squared: 0.8015951979669647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/17 18:21:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré dans les artifacts de MLflow.\n",
      "Modèle enregistré dans le Model Registry avec le nom : CaliforniaHousingRandomForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CaliforniaHousingRandomForest'.\n",
      "Created version '1' of model 'CaliforniaHousingRandomForest'.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le MSE mesure l'erreur quadratique moyenne entre les valeurs prédites et les valeurs réelles. Une valeur de 0.2316 indique que l'erreur moyenne quadratique est faible.\n",
    "\n",
    "Le RMSE (racine carrée du MSE) permet une interprétation plus intuitive puisqu'il est exprimé dans la même unité que la variable cible.\n",
    "Une valeur de 0.4812 montre une erreur relativement faible dans les prédictions.\n",
    "\n",
    "La MAE indique une erreur moyenne absolue de 0.3155, ce qui signifie que les prédictions s'écartent en moyenne de 0.3155 de la valeur réelle.\n",
    "\n",
    "Le R² montre que le modèle explique environ 80% de la variance des données cibles, ce qui reflète une bonne capacité explicative."
   ],
   "id": "cf925712b4c3b071"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **3- Gradient Boosting**",
   "id": "9e0dbf8f67192c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:22:39.003869Z",
     "start_time": "2025-01-17T17:22:26.756048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données\n",
    "file_path = '../data/processed/housing_standardized.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Définir (features) et la variable cible (target)\n",
    "X = data.drop(columns=['MedHouseVal'])\n",
    "y = data['MedHouseVal']\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de tests\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Début de l'expérience MLflow\n",
    "mlflow.set_experiment(\"California Housing Gradient Boosting\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Gradient Boosting Model\"):\n",
    "    # Initialiser et entraîner le modèle Gradient Boosting\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcul des métriques\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Racine carrée du MSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Enregistrer les paramètres\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "\n",
    "    # Enregistrer les métriques\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R-squared\", r2)\n",
    "\n",
    "    # Afficher les métriques\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "\n",
    "    # Enregistrer le modèle\n",
    "    mlflow.sklearn.log_model(model, \"gradient_boosting_model\")\n",
    "    print(\"Modèle enregistré dans MLflow.\")"
   ],
   "id": "4f90d6e2e9cf6ab1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/17 18:22:26 INFO mlflow.tracking.fluent: Experiment with name 'California Housing Gradient Boosting' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.25665392313463087\n",
      "Root Mean Squared Error (RMSE): 0.5066102280201524\n",
      "Mean Absolute Error (MAE): 0.35231127289581704\n",
      "R-squared: 0.7801057570989314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/17 18:22:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré dans MLflow.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le MSE est légèrement plus élevé que celui de Random Forest, traduisant des prédictions un peu moins précises.\n",
    "\n",
    "Le RMSE, à 0.5066, reflète une erreur modérée dans les prédictions.\n",
    "\n",
    "La MAE est de 0.3523, une performance correcte mais inférieure à Random Forest.\n",
    "\n",
    "Le R² indique que le modèle explique 78% de la variance des données, ce qui est une bonne performance mais légèrement inférieure à Random Forest."
   ],
   "id": "afb7e256a5906498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  Choix du meilleur modèle\n",
    "\n",
    "Après avoir comparé les résultats des trois modèles, le Random Forest est le modèle qui offre les meilleures performances globales :\n",
    "\n",
    "Erreurs plus faibles : Les métriques MSE, RMSE et MAE sont toutes inférieures, ce qui indique une précision accrue dans les prédictions.\n",
    "R² supérieur : Random Forest explique 80% de la variance des données, surpassant Gradient Boosting (78%) et la Régression Linéaire (65%).\n",
    "Robustesse : Random Forest est connu pour bien s'adapter aux ensembles de données complexes et variés.\n",
    "\n",
    "En conclusion, bien que la régression linéaire soit simple et interprétable, et que le Gradient Boosting ait des performances correctes, le Random Forest est clairement le choix optimal pour cette tâche grâce à ses meilleures performances sur l'ensemble des métriques."
   ],
   "id": "93a24affdac31643"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
